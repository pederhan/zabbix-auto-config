# IMPORTANT

* Source host max age can't be lower than the source collector update interval. If it is, hosts will flip-flop between enabled and disabled due to being removed from the source hosts table, then added again by the source collector. We can still remove stale hosts at a fairly frequent interval, but the max age should be at least as high as the source collector update interval.

* Investigate why a bunch of hosts that should have been removed were not removed. Why? When querying the tables manually, the hosts weren't there, but in the program, they somehow were. WTF?

~~ Need to fetch all hostnames from `hosts_source`, all hostnames from `hostnames`, then check which ones we should remove. ~~

# PROBABLY A GOOD IDEA

* Synchronization object that lets us know when all sources have finished collecting at least once. Or maybe not? We can just remove stale hosts whenever we want...
* Max source queue size. What to do when it's full? Discard, block or throw exception?
* Add index to `hosts` table for `data->>'enabled'` field:
    ```sql
    CREATE INDEX idx_hosts_on_enabled_true
    ON hosts ((data->>'enabled'))
    WHERE (data->>'enabled')::boolean IS TRUE;
    ```
* Add configuration for max source host age and frequency of stale source host removal.
* Add indexes for the `data->'hostname'`, `data->'sources'`, and `timestamp` fields in the `hosts_source` table.
* Add index for `data->>'enabled'` field in the `hosts` table.
    * This field is queried by the Zabbix host, hostgroup and template processes. So at least 3:1 ratio of reads to writes.

# MAYBE

* Bulk insertion. Fetch as many hosts as possible with a 1 sec timeout, then use all hosts to perform a bulk insertion. It will still be many operations however, so how performant will it be? The only benefit is that we re-use the same transaction. Maybe better because of fewer disk writes on the DB side?
    * If we do this, we need to ensure we don't have duplicates in the queue. We can either do this by using tuples in a set, or by manually filtering out duplicates.